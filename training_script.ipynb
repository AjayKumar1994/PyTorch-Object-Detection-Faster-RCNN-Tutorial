{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor, EarlyStopping\n",
    "from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pytorch_faster_rcnn_tutorial.datasets import ObjectDetectionDataSet\n",
    "from pytorch_faster_rcnn_tutorial.faster_RCNN import FasterRCNN_lightning\n",
    "from pytorch_faster_rcnn_tutorial.faster_RCNN import get_fasterRCNN_resnet\n",
    "from pytorch_faster_rcnn_tutorial.transformations import Clip, ComposeDouble\n",
    "from pytorch_faster_rcnn_tutorial.transformations import AlbumentationWrapper\n",
    "from pytorch_faster_rcnn_tutorial.transformations import FunctionWrapperDouble\n",
    "from pytorch_faster_rcnn_tutorial.transformations import normalize_01\n",
    "from pytorch_faster_rcnn_tutorial.utils import get_filenames_of_path, collate_double\n",
    "from pytorch_faster_rcnn_tutorial.utils import log_mapping_neptune\n",
    "from pytorch_faster_rcnn_tutorial.utils import log_model_neptune\n",
    "from pytorch_faster_rcnn_tutorial.utils import log_packages_neptune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "params = {'BATCH_SIZE': 2,\n",
    "          'OWNER': 'johschmidt42',  # set your name here, e.g. johndoe22\n",
    "          'SAVE_DIR': None,  # checkpoints will be saved to cwd\n",
    "          'LOG_MODEL': False,  # whether to log the model to neptune after training\n",
    "          'GPU': 1,  # set to None for cpu training\n",
    "          'LR': 0.001,\n",
    "          'PRECISION': 32,\n",
    "          'CLASSES': 2,\n",
    "          'SEED': 42,\n",
    "          'PROJECT': 'Heads',\n",
    "          'EXPERIMENT': 'heads',\n",
    "          'MAXEPOCHS': 500,\n",
    "          'BACKBONE': 'resnet34',\n",
    "          'FPN': False,\n",
    "          'ANCHOR_SIZE': ((32, 64, 128, 256, 512),),\n",
    "          'ASPECT_RATIOS': ((0.5, 1.0, 2.0),),\n",
    "          'MIN_SIZE': 1024,\n",
    "          'MAX_SIZE': 1024,\n",
    "          'IMG_MEAN': [0.485, 0.456, 0.406],\n",
    "          'IMG_STD': [0.229, 0.224, 0.225],\n",
    "          'IOU_THRESHOLD': 0.5\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api key\n",
    "api_key = os.environ['NEPTUNE']  # if this throws an error, you didn't set your env var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save directory\n",
    "if not params['SAVE_DIR']:\n",
    "    save_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root directory\n",
    "root = pathlib.Path('pytorch_faster_rcnn_tutorial/data/heads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input and target files\n",
    "inputs = get_filenames_of_path(root / 'input')\n",
    "targets = get_filenames_of_path(root / 'target')\n",
    "\n",
    "inputs.sort()\n",
    "targets.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping\n",
    "mapping = {\n",
    "    'head': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training transformations and augmentations\n",
    "transforms_training = ComposeDouble([\n",
    "    Clip(),\n",
    "    AlbumentationWrapper(albumentation=A.HorizontalFlip(p=0.5)),\n",
    "    AlbumentationWrapper(albumentation=A.RandomScale(p=0.5, scale_limit=0.5)),\n",
    "    # AlbuWrapper(albu=A.VerticalFlip(p=0.5)),\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation transformations\n",
    "transforms_validation = ComposeDouble([\n",
    "    Clip(),\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test transformations\n",
    "transforms_test = ComposeDouble([\n",
    "    Clip(),\n",
    "    FunctionWrapperDouble(np.moveaxis, source=-1, destination=0),\n",
    "    FunctionWrapperDouble(normalize_01)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seed\n",
    "seed_everything(params['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training validation test split\n",
    "inputs_train, inputs_valid, inputs_test = inputs[:12], inputs[12:16], inputs[16:]\n",
    "targets_train, targets_valid, targets_test = targets[:12], targets[12:16], targets[16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset training\n",
    "dataset_train = ObjectDetectionDataSet(inputs=inputs_train,\n",
    "                                       targets=targets_train,\n",
    "                                       transform=transforms_training,\n",
    "                                       use_cache=True,\n",
    "                                       convert_to_format=None,\n",
    "                                       mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset validation\n",
    "dataset_valid = ObjectDetectionDataSet(inputs=inputs_valid,\n",
    "                                       targets=targets_valid,\n",
    "                                       transform=transforms_validation,\n",
    "                                       use_cache=True,\n",
    "                                       convert_to_format=None,\n",
    "                                       mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset test\n",
    "dataset_test = ObjectDetectionDataSet(inputs=inputs_test,\n",
    "                                      targets=targets_test,\n",
    "                                      transform=transforms_test,\n",
    "                                      use_cache=True,\n",
    "                                      convert_to_format=None,\n",
    "                                      mapping=mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader training\n",
    "dataloader_train = DataLoader(dataset=dataset_train,\n",
    "                              batch_size=params['BATCH_SIZE'],\n",
    "                              shuffle=True,\n",
    "                              num_workers=0,\n",
    "                              collate_fn=collate_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader validation\n",
    "dataloader_valid = DataLoader(dataset=dataset_valid,\n",
    "                              batch_size=1,\n",
    "                              shuffle=False,\n",
    "                              num_workers=0,\n",
    "                              collate_fn=collate_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader test\n",
    "dataloader_test = DataLoader(dataset=dataset_test,\n",
    "                             batch_size=1,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0,\n",
    "                             collate_fn=collate_double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neptune logger\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=api_key,\n",
    "    project_name=f'{params[\"OWNER\"]}/{params[\"PROJECT\"]}',  # use your neptune name here\n",
    "    experiment_name=params['EXPERIMENT'],\n",
    "    params=params\n",
    ")\n",
    "\n",
    "assert neptune_logger.name  # http GET request to check if the project exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model init\n",
    "model = get_fasterRCNN_resnet(num_classes=params['CLASSES'],\n",
    "                              backbone_name=params['BACKBONE'],\n",
    "                              anchor_size=params['ANCHOR_SIZE'],\n",
    "                              aspect_ratios=params['ASPECT_RATIOS'],\n",
    "                              fpn=params['FPN'],\n",
    "                              min_size=params['MIN_SIZE'],\n",
    "                              max_size=params['MAX_SIZE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightning init\n",
    "task = FasterRCNN_lightning(model=model, lr=params['LR'], iou_threshold=params['IOU_THRESHOLD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "checkpoint_callback = ModelCheckpoint(monitor='Validation_mAP', mode='max')\n",
    "learningrate_callback = LearningRateMonitor(logging_interval='step', log_momentum=False)\n",
    "early_stopping_callback = EarlyStopping(monitor='Validation_mAP', patience=50, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer init\n",
    "trainer = Trainer(gpus=params['GPU'],\n",
    "                  precision=params['PRECISION'],  # try 16 with enable_pl_optimizer=False\n",
    "                  callbacks=[checkpoint_callback, learningrate_callback, early_stopping_callback],\n",
    "                  default_root_dir=params['SAVE_DIR'],  # where checkpoints are saved to\n",
    "                  logger=neptune_logger,\n",
    "                  log_every_n_steps=1,\n",
    "                  num_sanity_val_steps=0,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "trainer.max_epochs = params['MAXEPOCHS']\n",
    "trainer.fit(task,\n",
    "            train_dataloader=dataloader_train,\n",
    "            val_dataloaders=dataloader_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start testing\n",
    "trainer.test(ckpt_path='best', test_dataloaders=dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log packages\n",
    "log_packages_neptune(neptune_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log mapping as table\n",
    "log_mapping_neptune(mapping, neptune_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log model\n",
    "if params['LOG_MODEL']:\n",
    "    checkpoint_path = pathlib.Path(checkpoint_callback.best_model_path)\n",
    "    log_model_neptune(checkpoint_path=checkpoint_path,\n",
    "                      save_directory=pathlib.Path.home(),\n",
    "                      name='best_model.pt',\n",
    "                      neptune_logger=neptune_logger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
